## Week 54 – Q‑learning and off‑policy control

- **Reading:** Chapter 22 section 22.6 continued, focusing on **Q‑learning** as an off‑policy method and its convergence properties under certain conditions.aima.berkeley+1​

- **Coding:**

   - Implement **Q‑learning** on the same gridworld and compare learned policies and learning curves with SARSA under similar exploration settings.stonybrook+1​

   - Add logging of max Q‑value changes per iteration to visualize convergence.aima.berkeley+1​

- **Reflection:** Write a short comparison of **SARSA vs. Q‑learning**, highlighting on‑policy vs. off‑policy updates and how they behave differently in environments with stochastic transitions or risky actions.modanesh.github+1​