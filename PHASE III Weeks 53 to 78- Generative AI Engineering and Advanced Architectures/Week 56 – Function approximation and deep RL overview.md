## Week 56 – Function approximation and deep RL overview

- **Reading:** Chapter 22 section 22.8 on **function approximation** for value functions/policies and the concluding discussion that connects tabular RL to deep RL approaches.aima.berkeley+1​

- **Coding:**

   - Replace your tabular Q‑function with a **linear function approximator** or a small neural network (using your DL framework) on a slightly larger state space (e.g., continuous positions discretized into features).aikosh.indiaai+1​

   - Evaluate stability and performance vs. the tabular version, noting any divergence issues.aikosh.indiaai+1​

- **Reflection:** In 1 page, write a “Reinforcement Learning summary” covering bandits, MC, TD, SARSA, Q‑learning, and function approximation, and link them to your earlier **MDP** and **decision‑theory** work.aima.berkeley+1​