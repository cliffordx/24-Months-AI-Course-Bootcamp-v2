## Week 58 – Probabilistic models + RL

- **Reading:** Briefly revisit Chapters 13–14 (BNs and HMMs) with an eye toward **model‑based RL**, focusing on how learned models can replace known transition/reward models.aima.berkeley+1​

- **Coding:**

   - In a small environment, **estimate transition probabilities and rewards** from experience, fit a simple empirical model, and then run value iteration or policy iteration on that model.stonybrook+1​

   - Compare this model‑based approach with model‑free Q‑learning in terms of sample efficiency and performance.aima.berkeley+1​

- **Reflection:** Summarize differences between model‑free and model‑based RL and where your earlier probabilistic modeling skills (BNs, HMMs) could help in building world models.modanesh.github+1​