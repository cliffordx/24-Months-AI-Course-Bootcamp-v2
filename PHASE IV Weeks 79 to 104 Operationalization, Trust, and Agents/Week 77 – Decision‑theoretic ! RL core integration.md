## Week 77 – Decision‑theoretic / RL core integration

- **Reading:** Skim Chapters 16–17 and the summary of Chapter 22 to recall decision networks, MDPs, and RL’s role in learning policies.aima.berkeley+1​

- **Coding / design:**

   - Choose whether your capstone’s “brain” is primarily an **MDP/RL component** or a classical planner with occasional RL (e.g., for parameter tuning or exploration strategies).aima.berkeley+1​

   - Implement or adapt a policy module: e.g., an MDP policy via value iteration, or a Q‑learning/SARSA policy that selects actions given the current state or belief state.stonybrook+1​

- **Reflection:** In ½–1 page, explain why you chose model‑free vs. model‑based control and how you expect the decision module to interact with planning and probabilistic reasoning modules.aima.berkeley+1​