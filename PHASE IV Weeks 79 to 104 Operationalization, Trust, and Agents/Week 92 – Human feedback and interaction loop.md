## Week 92 – Human feedback and interaction loop

- **Reading:** Revisit AIMA’s material on human–AI interaction and preference/utility modeling, plus one modern piece on **RLHF or human‑in‑the‑loop LLM agents**.aclanthology+2​

- **Experiments:**

   - Design a simple **feedback loop**: e.g., allow a human user (you) to rate or correct outputs from your system (plans, recommendations, responses) and log those corrections.nlp.ucsc+1​

   - Implement a basic adaptation mechanism that uses this feedback to update preferences, weights, or rules (even if just re‑ranking or rule‑tweaking rather than full RLHF).projectpro+1​

- **Reflection:** Write a page on what kinds of human feedback were most useful, where automation is safe vs. where oversight is necessary, and how this aligns with AIMA’s discussion of **uncertain objectives and safe AI**.studocu+1​