## Week 82 – Robustness, safety, and ethics in your system

- **Reading:** Re‑read key sections of Chapters 26–27 on robotics safety, preference learning, human–robot interaction, and ethical/safety concerns in AI.lib.ysu+2​

- **Coding / design:**

   - Identify at least 2–3 **failure modes** or safety risks for your system (e.g., unsafe plans, biased recommendations, LLM hallucinations) and build tests that intentionally trigger them.thoughtworks+1​

   - Implement mitigation mechanisms: constraint checks on plans, post‑hoc LLM output filters, conservative reward functions, or human‑in‑the‑loop confirmation steps.studocu+1​

- **Reflection:** Produce a short “Safety and Ethics” section for your eventual report, clearly stating limitations, mitigations, and open risks that remain.studocu+1​