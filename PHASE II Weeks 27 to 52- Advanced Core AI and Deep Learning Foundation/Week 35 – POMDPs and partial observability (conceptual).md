## Week 35 – POMDPs and partial observability (conceptual)

- **Reading:** Chapter 17 sections on **partially observable MDPs (POMDPs)** and belief‑state MDPs; focus on conceptual understanding more than detailed algorithms.[lib.ysu+1](http://lib.ysu.am/disciplines_bk/b7707dde83ee24b2b23999b4df5fd988.pdf)​

- **Coding / exercises:**

   - Modify your gridworld so the agent only partially observes its state (e.g., noisy sensor about position) and implement a simple belief‑state representation that updates via Bayes’ rule based on actions and observations.[aima.berkeley](https://aima.cs.berkeley.edu/contents.html)​

   - Simulate a simple policy in this POMDP‑like setting and log belief trajectories.[aima.berkeley](https://aima.cs.berkeley.edu/contents.html)​

- **Reflection:** Explain how POMDP belief states unify the temporal probabilistic reasoning from Chapter 14 with decision‑theoretic control, and why exact POMDP solutions are challenging in practice.[lib.ysu+1](http://lib.ysu.am/disciplines_bk/b7707dde83ee24b2b23999b4df5fd988.pdf)​