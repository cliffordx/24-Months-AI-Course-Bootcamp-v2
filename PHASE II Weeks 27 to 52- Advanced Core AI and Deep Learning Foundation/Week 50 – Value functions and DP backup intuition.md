## Week 50 – Value functions and DP backup intuition

- **Reading:** Chapter 22 section 22.3 on **value functions** Vπ(s)V^\\pi(s)Vπ(s) and Qπ(s,a)Q^\\pi(s,a)Qπ(s,a) and their Bellman equations, revisiting dynamic programming ideas from your MDP work.aima.berkeley+1​

- **Coding:**

   - Re‑implement or adapt **policy evaluation** and **value iteration** for a small gridworld MDP using the Bellman backups described in the RL chapter (even if you did this earlier, focus on RL interpretation).stonybrook+1​

   - Compare convergence behavior and resulting optimal policies with those you obtained in Weeks 33–34.modanesh.github+1​

- **Reflection:** Write about how value functions connect your earlier decision‑theoretic MDP work (Chapter 17) to RL algorithms and why Bellman equations are central to both.aima.berkeley+1​