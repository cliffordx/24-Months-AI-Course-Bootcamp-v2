## Week 39 – Linear models and perceptron

- **Reading:** Chapter 19 sections on **linear models**, perceptron learning, and gradient‑based optimization for regression/classification.[aima.berkeley+1](https://aima.cs.berkeley.edu/contents.html)​

- **Coding / exercises:**

   - Implement the **perceptron algorithm** and logistic regression from scratch for a 2‑D or low‑dimensional dataset, including mini‑batch gradient descent.[aimacode.github+1](https://aimacode.github.io/aima-exercises/concept-learning-exercises/)​

   - Compare decision trees vs. linear models on the same dataset in terms of accuracy, robustness to noise, and interpretability.[stonybrook+1](https://www3.cs.stonybrook.edu/\~sael/teaching/cse537/Slides/chapter20a.pdf)​

- **Reflection:** Write a short comparison of when linear models are appropriate vs. trees, focusing on feature representation and decision boundary shape.[modanesh.github+1](https://modanesh.github.io/assets/Summary%20Artificial%20Intelligence%20A%20Modern%20Approach.pdf)​