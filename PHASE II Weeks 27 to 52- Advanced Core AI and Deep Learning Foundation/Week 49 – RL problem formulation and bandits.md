## Week 49 – RL problem formulation and bandits

- **Reading (1–2 sessions):** Chapter 22 “Reinforcement Learning” sections 22.1–22.2, covering the RL framework (states, actions, rewards, return, policy) and **multi‑armed bandits** as the simplest RL setting.aima.berkeley+1​

- **Coding (1–2 sessions):**

   - Implement k‑armed bandits with several strategies: greedy, ε‑greedy, and optimistic initialization.aimacode.github+1​

   - Plot average reward and regret over time for each strategy on a fixed bandit instance.aimacode.github+1​

- **Reflection:** In ½–1 page, explain how the RL problem differs from supervised learning, emphasizing **trial‑and‑error**, delayed reward, and exploration–exploitation trade‑offs.modanesh.github+1​